# -*- coding: utf-8 -*-
"""Copy of Wine Quality Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VsAsP_Nr2tPDECkgib65E6zUZskC4_d5
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df=pd.read_csv("/content/WineQT.csv")

from sklearn.linear_model import LinearRegression ,LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.svm import SVC ,SVR
from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, classification_report
from sklearn.model_selection import GridSearchCV

# For Data Processing
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

# For Data Visualization
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Miscellaneous
import os
import random

df['quality'] = df['quality']-3
df

df.describe()[1:].T.style.background_gradient(cmap='Blues')

fig = go.Figure(data=[go.Pie(labels=df['quality'].value_counts().index, values=df['quality'].value_counts(), hole=.3)])
fig.update_layout(legend_title_text='Quality')
fig.show()

fig = px.imshow(df.corr(),color_continuous_scale="Blues")
fig.update_layout(height=750)
fig.show()

df_corr_bar = abs(df.corr()['quality']).sort_values()[:-1]
fig = px.bar(df_corr_bar, orientation='h', color_discrete_sequence =['#4285f4']*len(df_corr_bar))
fig.update_layout(showlegend=False)
fig.show()

fig = go.Figure()

for x in range(6):
    fig.add_trace(go.Box(
        x=df[df['quality']==x]['volatile acidity'],
        y=df[df['quality']==x]['quality'], name='Quality '+str(x)
    ))

fig.update_layout(
    yaxis_title='quality', xaxis_title='volatile acidity'
)
fig.update_traces(orientation='h')
fig.show()

fig = px.scatter(df, x="total sulfur dioxide", y="free sulfur dioxide", color=df['quality'],  color_continuous_scale='Blues')
fig.update_layout(legend_title_text='Quality')

fig = go.Figure()

for x in range(6):
    fig.add_trace(go.Box(
        x=df[df['quality']==x]['citric acid'],
        y=df[df['quality']==x]['quality'], name='Quality '+str(x)
    ))

fig.update_layout(
    yaxis_title='quality', xaxis_title='citric acid'
)
fig.update_traces(orientation='h')
fig.show()

fig = px.scatter(df, x="fixed acidity", y="density", color=df['quality'],  color_continuous_scale='Blues')
fig.update_layout(legend_title_text='Quality')

fig = go.Figure()

for x in range(6):
    fig.add_trace(go.Box(
        x=df[df['quality']==x]['sulphates'],
        y=df[df['quality']==x]['quality'], name='Quality '+str(x)
    ))

fig.update_layout(
    yaxis_title='quality', xaxis_title='sulphates'
)
fig.update_traces(orientation='h')
fig.show()

fig = px.scatter(df, x="citric acid", y="volatile acidity", color=df['quality'],  color_continuous_scale='Blues')
fig.update_layout(legend_title_text='Quality')

fig = px.scatter(df, x="citric acid", y="volatile acidity", color=df['quality'],  color_continuous_scale='Blues')
fig.update_layout(legend_title_text='Quality')

df.describe().T[['min', 'max']][:-1].style.background_gradient(cmap='Blues')

for col in ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',
       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',
       'pH', 'sulphates', 'alcohol']:
    df[col] = df[col]/df[col].max()

features = np.array(df[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',
       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',
       'pH', 'sulphates', 'alcohol']])
labels = np.array(df['quality'])

x_train, x_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=0)

model_comparison = {}

parameters = {'C': [6,8,10,12,14,16], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}

svc_model = SVC()

clf = GridSearchCV(svc_model, parameters)
print("Searching for best hyperparameters ...")
clf.fit(x_train, y_train)
print(f'Best Hyperparameters: {clf.best_params_}')

y_pred = clf.predict(x_val)
model_comparison['SVC'] = [accuracy_score(y_val,y_pred), f1_score(y_val,y_pred, average='weighted')]
print('\n')
print(classification_report(y_val,y_pred, zero_division=1))

parameters = {'max_depth': [5,10,15,20]}

Tree_model = DecisionTreeClassifier()

clf = GridSearchCV(Tree_model, parameters)
print("Searching for best hyperparameters ...")
clf.fit(x_train, y_train)
print(f'Best Hyperparameters: {clf.best_params_}')

y_pred = clf.predict(x_val)
model_comparison['DecisionTreeClassifier'] = [accuracy_score(y_val,y_pred), f1_score(y_val,y_pred, average='weighted')]
print('\n')
print(classification_report(y_val,y_pred, zero_division=1))

parameters = {'n_neighbors': [10,20,30,40,50]}

K_model = KNeighborsClassifier()

clf = GridSearchCV(K_model, parameters)
print("Searching for best hyperparameters ...")
clf.fit(x_train, y_train)
print(f'Best Hyperparameters: {clf.best_params_}')

y_pred = clf.predict(x_val)
model_comparison['KNeighborsClassifier'] = [accuracy_score(y_val,y_pred), f1_score(y_val,y_pred, average='weighted')]
print('\n')
print(classification_report(y_val,y_pred, zero_division=1))

model_comparison_df = pd.DataFrame.from_dict(model_comparison).T
model_comparison_df.columns = ['Accuracy', 'F1 Score']
model_comparison_df = model_comparison_df.sort_values('F1 Score', ascending=True)
model_comparison_df.style.background_gradient(cmap='Blues')

fig = go.Figure(data=[
    go.Bar(name='F1 Score', y=model_comparison_df.index, x=model_comparison_df['F1 Score'], orientation='h'),
    go.Bar(name='Accuracy', y=model_comparison_df.index, x=model_comparison_df['Accuracy'], orientation='h')
])
fig.update_layout(barmode='group')
fig.show()

